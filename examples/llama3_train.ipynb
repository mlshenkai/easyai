{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-24T12:02:53.857327Z",
     "start_time": "2024-06-24T12:02:53.849914Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('/code-online/code/easy_ai')\n",
    "import os\n",
    "os.environ[\"GRADIO_SERVER_PORT\"] = \"7474\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:02:54.393863Z",
     "start_time": "2024-06-24T12:02:54.385876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "from easyai.configs import get_train_args\n",
    "\n",
    "sys.argv = [\"cli\", \"train\", \"--stage\", \"pt\", \"--do_train\", \"True\", \"--model_name_or_path\", \"/code-online/modelscope/llama3-chinese-Instruct\", \"--output_dir\", \"/code/logs\", \"--template\", \"default\", \"--dataset_dir\", \"/code-online/code/easy_ai/data\", \"--dataset\", \"alpaca_zh\", \"--finetuning_type\", \"full\"]"
   ],
   "id": "7e5be36fde3ee41f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:02:55.141460Z",
     "start_time": "2024-06-24T12:02:54.934898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.argv.pop(1)\n",
    "model_args, data_args, training_args, finetuning_args, generating_args = get_train_args()"
   ],
   "id": "e6904c1d83861871",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:2052] 2024-06-24 20:02:54,970 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1727] 2024-06-24 20:02:55,123 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/24/2024 20:02:55 - WARNING - easyai.configs.parser - We recommend enable mixed precision training.\n",
      "06/24/2024 20:02:55 - INFO - easyai.configs.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: None\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:03:51.194267Z",
     "start_time": "2024-06-24T12:03:51.185005Z"
    }
   },
   "cell_type": "code",
   "source": "training_args",
   "id": "fb572759d52079f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTrainingArguments(output_dir='/code/logs', overwrite_output_dir=False, do_train=True, do_eval=False, do_predict=False, eval_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, lr_scheduler_kwargs={}, warmup_ratio=0.0, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='/code/logs/runs/Jun24_20-02-54_sk', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, save_safetensors=True, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name='/code/logs', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None), deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, hub_always_push=False, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, eval_do_concat_batches=True, fp16_backend='auto', evaluation_strategy=None, push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, split_batches=None, include_tokens_per_second=False, include_num_input_tokens_seen=False, neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, sortish_sampler=False, predict_with_generate=False, generation_max_length=None, generation_num_beams=None, generation_config=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:07:41.313898Z",
     "start_time": "2024-06-24T12:07:41.307249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from easyai.data import get_dataset\n",
    "from easyai.models import load_tokenizer, load_model\n"
   ],
   "id": "4d0b95df0487c0ef",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:07:42.814165Z",
     "start_time": "2024-06-24T12:07:42.369150Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = load_tokenizer(model_args)",
   "id": "a459c172f1982f6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2106] 2024-06-24 20:07:42,376 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2106] 2024-06-24 20:07:42,378 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2106] 2024-06-24 20:07:42,379 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2106] 2024-06-24 20:07:42,380 >> loading file tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-24 20:07:42,782 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:07:50.483868Z",
     "start_time": "2024-06-24T12:07:45.709745Z"
    }
   },
   "cell_type": "code",
   "source": "datasets = get_dataset(model_args=model_args, data_args=data_args,training_args=training_args,stage=\"pt\", **tokenizer)\n",
   "id": "514f2b25abd3ea10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/24/2024 20:07:45 - INFO - easyai.data.loader - Loading dataset llamafactory/alpaca_zh...\n",
      "input_ids:\n",
      "[98739, 109425, 19000, 9080, 40053, 104654, 16325, 111689, 83747, 11883, 53610, 11571, 128001, 58119, 83125, 119101, 42246, 34226, 107246, 73686, 58653, 30046, 9174, 37026, 36668, 33748, 32648, 17792, 21043, 112352, 33748, 108663, 9554, 33748, 32648, 122996, 31968, 39607, 76217, 66378, 23187, 89902, 69636, 16937, 86206, 109545, 124785, 32296, 1811, 37026, 36668, 33748, 32648, 17792, 19000, 102208, 19483, 113366, 16325, 101307, 104087, 37507, 104087, 82042, 125276, 30590, 109589, 113294, 118329, 42052, 28037, 125044, 33563, 105298, 88356, 28037, 105509, 1811, 128001, 105212, 74770, 105414, 18655, 106189, 98184, 105226, 105838, 37507, 111689, 83747, 35894, 102146, 116028, 108208, 11571, 128001, 31540, 88356, 21990, 126369, 9554, 48706, 33764, 110593, 123100, 109829, 11571, 128001, 50338, 69962, 101365, 54493, 72456, 109425, 111478, 1811, 128001, 90112, 20834, 48044, 33748, 32648, 111478, 70203, 25333, 9554, 27452, 45829, 91495, 50338, 69962, 103282, 21043, 109425, 102301, 9554, 1811, 128001, 54581, 118553, 73548, 9554, 102301, 53229, 22649, 128001, 32218, 20834, 17792, 49792, 118034, 9554, 76208, 19483, 88367, 109589, 128001, 32218, 108448, 109683, 120074, 55642, 89902, 9554, 64803, 19483, 27452, 45829, 128001, 45163, 88852, 106808, 45829, 46281, 120143, 13646, 36343, 47770, 72234, 18184, 106884, 120143, 13646, 36343, 198, 43511, 97655, 104198, 33122, 72516, 102149, 1811, 128001, 107047, 103129, 48972, 42421, 13325, 116196, 248, 22656, 9174, 76982, 107928, 22656, 86206, 110835, 33765, 3922, 105745, 16325, 32938, 105318, 9554, 106738, 46729, 82900, 34208, 106738, 9554, 105745, 82900, 1811, 109530, 115973, 38093, 45059, 15120, 70542, 110553, 3922, 110553, 115274, 106738, 46729, 82900, 3490, 475, 5826, 27907, 333, 2479, 18635, 14629, 8, 624, 220, 18, 512, 262, 4311, 284, 528, 18635, 14629, 58, 16, 2608, 262, 3953, 284, 528, 18635, 14629, 58, 17, 2526, 1473, 17645, 284, 610, 7, 4311, 611, 3953, 340, 1374, 446, 791, 5578, 1396, 315, 4311, 574, 25, 330, 489, 5578, 8, 128001, 58653, 17297, 115070, 38574, 102936, 3922, 93233, 20834, 48044, 57106, 83601, 119, 106808, 45829, 9174, 1, 98711, 120396, 21555, 120, 46961, 113433, 102048, 227, 104735, 222, 3922, 107163, 102149, 42399, 35287, 36827, 35894, 1, 128001, 19000, 87, 15568, 112, 17905, 104862, 111930, 103, 90112, 23187, 33904, 23897, 125414, 67117, 9174, 69, 2120, 8, 284, 220, 17, 87, 489, 220, 16, 128001, 58119, 15120, 124684, 3922, 125992, 106808, 45829, 113520, 114165, 103282, 124778, 19361, 110999, 9174, 105212, 104724, 21601, 103229, 35287, 124082, 1811, 128001, 45059, 48044, 107963, 106885, 88852, 83125, 9554, 104251, 37689, 61496, 9174, 15120, 70542, 17039, 110553, 21405, 31958, 41920, 120792, 33208, 81802, 111, 116840, 9554, 113299, 124376, 35287, 34226, 45736, 9554, 126287, 5486, 34226, 106146, 79982, 9554, 36827, 102146, 58721, 34208, 112027, 43240, 91985, 117332, 119702, 13079, 108, 56906, 1811, 128001, 113511, 90112, 114606, 110835, 65529, 64026, 104908, 99337, 31958, 9554, 113511, 54581, 9174, 65529, 16, 5232, 127392, 720, 65529, 17, 5232, 101057, 247, 45829, 128001, 19000, 90112, 118078, 111793, 41914, 22656, 127128, 17905, 126291, 62543, 15120, 111879, 86741, 198, 50182, 101067, 56, 14361, 220, 18485, 128001, 45059, 15120, 70542, 120610, 95598, 87502, 87844, 35304, 107711, 104979, 9554, 106063, 66378, 16555, 228, 15308, 121, 117430, 9554, 80866, 24946, 128001, 19000, 90112, 118078, 106041, 17297, 72917, 119661, 77413, 64026, 104251, 67178, 48044, 117625, 198, 46281, 25580, 19361, 48044, 101987, 19000, 31809, 101634, 112313, 117834, 8107, 106196, 58850, 105989, 128001, 125510, 104908, 9554, 108321, 118664, 123344, 28542, 31091, 198, 114487, 101545, 48634, 5486, 105301, 101355, 241, 5486, 105140, 105578, 8192, 115, 114248, 28873, 128001, 18184, 90112, 23187, 83800, 45059, 82042, 58655, 40526, 18476, 198, 101630, 102283, 11589, 232, 33406, 128001, 78935, 26892, 8029, 81628, 23897, 105483, 102780, 119745, 198, 46281, 21405, 364, 30141, 6, 73958, 98657, 52084, 56438, 66677, 128001, 60843, 37985, 32938, 90112, 91386, 108847, 9554, 31634, 28542, 198, 103312, 107921, 108538, 109620, 83994, 103698, 103496, 41914, 128001, 115392, 33764, 104908, 9554, 124010, 51477, 48044, 102473, 87219, 198, 56235, 50211, 28190, 17905, 105062, 128001, 60843, 37985, 44388, 34048, 119585, 9554, 124010, 9174, 119585, 28038, 35287, 16937, 72718, 9554, 113333, 124031, 57106, 26123, 21043, 68171, 37, 13, 10016, 62314, 32938, 62543, 1811, 128001, 110367, 120143, 100207, 33122, 72516, 9554, 104424, 92553, 105226, 105838, 1811, 128001, 90112, 20834, 113882, 53229, 42506, 80866, 24946, 34547, 3922, 118125, 98739, 109425, 114835, 15120, 70542, 119992, 9554, 72238, 102456, 108042, 9174, 37689, 119684, 28190, 5486, 87217, 91994, 226, 5486, 105417, 106390, 101161, 109, 110745, 103858, 250, 1811, 128001, 116472, 93233, 110835, 41920, 24186, 71638, 87219, 9554, 27452, 45829, 1811, 128001, 114835, 48044, 19361, 37687, 44309, 126235, 37687, 121355, 3922, 113221, 127198, 107585, 15017, 238, 28425, 254, 90112, 101557, 230, 106594, 110123, 1811, 128001, 115392, 33764, 83800, 91547, 118664, 76208, 87502, 104424, 92553, 105226, 105838, 1811, 128001, 90112, 20834, 48044, 86206, 56026, 105196, 32296, 26592, 9554, 71638, 87219, 9554, 20379, 27452, 11571, 128001, 45163, 88852, 53953, 25446, 45277, 47770, 72234, 18184, 106808, 45829, 198, 23182, 11, 44196, 11, 19087, 128001, 32218, 20834, 126524, 54581, 105390, 40053, 90070, 83799, 37729, 106015, 128001, 62543, 48044, 89186, 9554, 113511, 73981, 106808, 198, 83898, 106, 79059, 34208, 117366, 128001, 107963, 43032, 88852, 38574, 102936, 198, 37026, 5162, 24, 8107, 123434, 3922, 109615, 110164, 104743, 43323, 112736, 19000, 106767, 52084, 9953, 79059, 1811, 104563, 26892, 67178, 35287, 124426, 3922, 122338, 126323, 9953, 79059, 41053, 64026, 51109, 43167, 35287, 91985, 22656, 1811, 128001, 54581, 110310, 109572, 105363, 126524, 106848, 128001, 62543, 15120, 38574, 111912, 126550, 66378, 28542, 9554, 54581, 198, 67287, 5232, 103478, 57106, 113333, 100179, 198, 114765, 9554, 110507, 5232, 28833, 19967, 109998, 5486, 124235, 108171, 5486, 104601, 13079, 115, 35304, 33122, 42052, 128001, 32218, 108448, 46091, 108306, 49792, 118034, 109589, 75320, 128001, 45163, 46885, 47770, 72234, 18184, 25141, 220, 18670, 16, 69905, 198, 34827, 220, 914, 11, 220, 2366, 15, 128001, 18184, 90112, 23187, 106649, 73981, 51477, 61075, 19113, 103760, 118504, 105838, 106015, 198, 83687, 105509, 128001, 90112, 23187, 87219, 31968, 62543, 48044, 50667, 29430, 198, 112352, 110835, 112169, 123025, 9554, 48634, 19, 45, 34208, 21, 45, 9554, 115147, 40862, 48634, 128001, 18184, 90112, 118078, 102216, 65854, 45059, 119100, 19000, 58543, 34972, 45277, 198, 104424, 92553, 128001, 112352, 90112, 23187, 83799, 103397, 9554, 122858, 198, 118188, 18184, 20, 16906, 246, 73361, 3922, 45736, 18184, 605, 16906, 246, 73361, 9554, 100543, 102, 83799, 128001, 118897, 104133, 19000, 90112, 23187, 33144, 32218, 105363, 17297, 48044, 122548, 198, 18, 11, 220, 20, 11, 220, 22, 11, 220, 24, 11, 1328, 128001, 32218, 108448, 48044, 53953, 25446, 40053]\n",
      "inputs:\n",
      "我们如何在日常生活中减少用水？<|end_of_text|>编辑文章，使其更吸引读者。\n",
      "自主机器人是计算机控制的机器，被编程执行特定任务而不需要任何人类输入。自主机器人在各个行业中被越来越广泛地应用，从制造业到医疗保健再到安全。<|end_of_text|>政府可以采取哪些策略来减少空气污染？<|end_of_text|>可再生能源的存在对环境有什么影响？<|end_of_text|>解释神经网络如何学习。<|end_of_text|>给出一个机器学习算法的例子，并解释它是如何工作的。<|end_of_text|>描述推荐系统的工作原理<|end_of_text|>列出人工智能的五个可能应用<|end_of_text|>列举自然语言处理任务的四个例子<|end_of_text|>将以下句子从一种时态转换为另一种时态\n",
      "他正在往商店走。<|end_of_text|>协助调试 Python 脚本。\n",
      "该脚本需要两个参数，游戏中所要求的玩家数量和玩的游戏数量。然后，它会生成一份报告，报告平均玩家数量。\n",
      "\n",
      "import sys\n",
      " \n",
      "if len(sys.argv) == 3:\n",
      "    players = int(sys.argv[1])\n",
      "    games = int(sys.argv[2]):\n",
      "\n",
      "average = str( players / games)\n",
      "print(\"The average number of players was: \" + average)<|end_of_text|>读下面的段落，找出一个比喻句子。\n",
      "\"我的烦恼长出了翅膀，飞走进了天空\"<|end_of_text|>在x轴上追踪给定函数以找到输出。\n",
      "f(x) = 2x + 1<|end_of_text|>编辑一句话，改变句子结构，让它更加有趣。\n",
      "政府已经加强了限制。<|end_of_text|>生成一个概括以下文章的创意标题。\n",
      "一份新报告表明二氧化碳水平的增加导致了更高的温度、更极端的天气事件和生物多样性的快速衰退。<|end_of_text|>比较给出的两个对象并提供简明的比较描述。\n",
      "对象1：苹果 \n",
      "对象2：橙子<|end_of_text|>在给定的笔记本电脑上撰写一篇评论\n",
      "联想Yoga 920<|end_of_text|>生成一份包含十种易于养护的独特盆栽植物的清单<|end_of_text|>在给定的情况下进行扩展并创造一个故事\n",
      "从前有一个住在小村庄里的年轻女孩<|end_of_text|>基于提供的材料提出甜点名称\n",
      "巧克力、草莓、夏威夷坚果<|end_of_text|>为给定产品生成广告口号\n",
      "亚马逊Prime<|end_of_text|>构建 SQL 查询以满足需求\n",
      "从表'sales' 中检索所有记录<|end_of_text|>总结所给书籍的要点\n",
      "爱丽丝漫游奇境记<|end_of_text|>针对提供的主题创建一个研究问题\n",
      "海平面上升<|end_of_text|>总结这部小说的主题。\n",
      "小说《了不起的盖茨比》是由F. Scott Fitzgerald所写。<|end_of_text|>开发一种在线商店的营销策略。<|end_of_text|>给出一些原料清单后，告诉我们如何制作一份简单的素食餐。\n",
      "意大利面、番茄、红洋葱、大蒜。<|end_of_text|>寻找两个二元分类问题的例子。<|end_of_text|>制作一个有说服力的说辞，为什么人们应该捐赠给慈善机构。<|end_of_text|>针对产品发布提出五种营销策略。<|end_of_text|>给出一个需要连续输入值的分类问题的示例？<|end_of_text|>将以下物品列表转换为句子\n",
      "apple, banana, orange<|end_of_text|>列出三个描述人的常见形容词<|end_of_text|>写一个有效的比较语句\n",
      "篮球和足球<|end_of_text|>概述以下段落\n",
      "自1969年以来，美国宇航员一直在探索月球。他们建造了基地，驾驶月球车并收集了样本。<|end_of_text|>描述你的城市中的三个地方<|end_of_text|>写一段关于一个人特点的描述\n",
      "姓名：阿比盖尔\n",
      "喜欢的东西：动作电影、法国菜、热衷于商业<|end_of_text|>列举三个人工智能应用程序<|end_of_text|>将日期转换为ISO 8601格式\n",
      "November 25, 2020<|end_of_text|>为给定短语创建首字母缩略词\n",
      "数字安全<|end_of_text|>给定问题编写一个等式\n",
      "计算两个方向相同的力4N和6N的净合力<|end_of_text|>为给定的博客生成潜在话题列表\n",
      "营销<|end_of_text|>计算给定形状的面积\n",
      "宽为5厘米，高为10厘米的矩形<|end_of_text|>猜测在给定序列中的下一个元素\n",
      "3, 5, 7, 9, __<|end_of_text|>列举一个物品常\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T09:37:55.156933Z",
     "start_time": "2024-06-24T09:37:40.758619Z"
    }
   },
   "cell_type": "code",
   "source": "model = load_model(tokenizer[\"tokenizer\"], model_args, finetuning_args, is_trainable=True, add_valuehead=False)",
   "id": "e1ba568646769ff8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:731] 2024-06-24 17:37:40,761 >> loading configuration file /code-online/modelscope/llama3-chinese-Instruct/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-24 17:37:40,762 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/code-online/modelscope/llama3-chinese-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3471] 2024-06-24 17:37:40,765 >> loading weights file /code-online/modelscope/llama3-chinese-Instruct/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-06-24 17:37:40,766 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-24 17:37:40,767 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2173837b5a04d9e9e1f23b146e18404"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4280] 2024-06-24 17:37:54,863 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-24 17:37:54,864 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /code-online/modelscope/llama3-chinese-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:915] 2024-06-24 17:37:54,870 >> loading configuration file /code-online/modelscope/llama3-chinese-Instruct/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-24 17:37:54,871 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/24/2024 17:37:54 - INFO - easyai.models.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "06/24/2024 17:37:54 - INFO - easyai.models.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/24/2024 17:37:54 - INFO - easyai.models.adapter - Upcasting trainable params to float32.\n",
      "06/24/2024 17:37:54 - INFO - easyai.models.adapter - Fine-tuning method: Full\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtokenizer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinetuning_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_trainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_valuehead\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/code-online/code/easy_ai/easyai/models/loader.py:177\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(tokenizer, model_args, finetuning_args, is_trainable, add_valuehead)\u001B[0m\n\u001B[1;32m    174\u001B[0m     patch_model(model, tokenizer, model_args, is_trainable, add_valuehead)\n\u001B[1;32m    175\u001B[0m     register_autoclass(config, model, tokenizer)\n\u001B[0;32m--> 177\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43minit_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinetuning_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_trainable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m add_valuehead:\n\u001B[1;32m    180\u001B[0m     model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLMWithValueHead\u001B[38;5;241m.\u001B[39mfrom_pretrained(model)\n",
      "File \u001B[0;32m/code-online/code/easy_ai/easyai/models/adapter.py:367\u001B[0m, in \u001B[0;36minit_adapter\u001B[0;34m(config, model, model_args, finetuning_args, is_trainable)\u001B[0m\n\u001B[1;32m    364\u001B[0m     cast_trainable_params_to_fp32 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m finetuning_args\u001B[38;5;241m.\u001B[39mfinetuning_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfull\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 367\u001B[0m     \u001B[43m_setup_full_tuning\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfinetuning_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_trainable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_trainable_params_to_fp32\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m finetuning_args\u001B[38;5;241m.\u001B[39mfinetuning_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfreeze\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    375\u001B[0m     _setup_freeze_tuning(\n\u001B[1;32m    376\u001B[0m         model,\n\u001B[1;32m    377\u001B[0m         model_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    380\u001B[0m         cast_trainable_params_to_fp32,\n\u001B[1;32m    381\u001B[0m     )\n",
      "File \u001B[0;32m/code-online/code/easy_ai/easyai/models/adapter.py:56\u001B[0m, in \u001B[0;36m_setup_full_tuning\u001B[0;34m(model, model_args, finetuning_args, is_trainable, cast_trainable_params_to_fp32)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(forbidden_module \u001B[38;5;129;01min\u001B[39;00m name \u001B[38;5;28;01mfor\u001B[39;00m forbidden_module \u001B[38;5;129;01min\u001B[39;00m forbidden_modules):\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cast_trainable_params_to_fp32:\n\u001B[0;32m---> 56\u001B[0m         param\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m     param\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T09:34:30.326532Z",
     "start_time": "2024-06-24T09:34:30.319088Z"
    }
   },
   "cell_type": "code",
   "source": "model_args\n",
   "id": "4d4db4a25a36358",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArguments(model_name_or_path='/code-online/modelscope/llama3-chinese-Instruct', adapter_name_or_path=None, adapter_folder=None, cache_dir=None, use_fast_tokenizer=True, resize_vocab=False, split_special_tokens=False, new_special_tokens=None, model_revision='main', low_cpu_mem_usage=True, quantization_bit=None, quantization_type='nf4', double_quantization=True, quantization_device_map=None, rope_scaling=None, flash_attn='auto', shift_attn=False, mixture_of_depths=None, use_unsloth=False, visual_inputs=False, moe_aux_loss_coef=None, disable_gradient_checkpointing=False, upcast_layernorm=False, upcast_lmhead_output=False, train_from_scratch=False, infer_backend='huggingface', vllm_maxlen=2048, vllm_gpu_util=0.9, vllm_enforce_eager=False, vllm_max_lora_rank=32, offload_folder='offload', use_cache=True, infer_dtype='auto', hf_hub_token=None, ms_hub_token=None, export_dir=None, export_size=1, export_device='cpu', export_quantization_bit=None, export_quantization_dataset=None, export_quantization_nsamples=128, export_quantization_maxlen=1024, export_legacy_format=False, export_hub_model_id=None, print_param_status=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T09:34:42.497927Z",
     "start_time": "2024-06-24T09:34:42.488862Z"
    }
   },
   "cell_type": "code",
   "source": "finetuning_args",
   "id": "a8580de4d9c6c193",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinetuningArguments(use_badam=False, badam_mode='layer', badam_start_block=None, badam_switch_mode='ascending', badam_switch_interval=50, badam_update_ratio=0.05, badam_mask_mode='adjacent', badam_verbose=0, use_galore=False, galore_target=['all'], galore_rank=16, galore_update_interval=200, galore_scale=0.25, galore_proj_type='std', galore_layerwise=False, pref_beta=0.1, pref_ftx=0.0, pref_loss='sigmoid', dpo_label_smoothing=0.0, kto_chosen_weight=1.0, kto_rejected_weight=1.0, simpo_gamma=0.5, ppo_buffer_size=1, ppo_epochs=4, ppo_score_norm=False, ppo_target=6.0, ppo_whiten_rewards=False, ref_model=None, ref_model_adapters=None, ref_model_quantization_bit=None, reward_model=None, reward_model_adapters=None, reward_model_quantization_bit=None, reward_model_type='lora', additional_target=None, lora_alpha=16, lora_dropout=0.0, lora_rank=8, lora_target=['all'], loraplus_lr_ratio=None, loraplus_lr_embedding=1e-06, use_rslora=False, use_dora=False, pissa_init=False, pissa_iter=4, pissa_convert=False, create_new_adapter=False, freeze_trainable_layers=2, freeze_trainable_modules=['all'], freeze_extra_modules=None, pure_bf16=False, stage='pt', finetuning_type='lora', use_llama_pro=False, freeze_vision_tower=True, train_mm_proj_only=False, plot_loss=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28034746ddc2877d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
