model:
  arch: blip2_qformer
  model_type: pretrain
  config:
    config:
      name: blip2_config
      args:
        blip2_vision_config:
          hidden_size: 1408
          intermediate_size: 6144
          num_hidden_layers: 39
          num_attention_heads: 16
          image_size: 224
          patch_size: 14
          hidden_act: gelu
          layer_norm_eps: 0.00001
          attention_dropout: 0.0
          initializer_range: 1e-10
          qkv_bias: True

        blip_2_qformer:
          vocab_size: 30522
          hidden_size: 768
          num_hidden_layers: 12
          num_attention_heads: 12
          intermediate_size: 3072
          hidden_act: "gelu"
          hidden_dropout_prob: 0.1
          attention_probs_dropout_prob: 0.1
          max_position_embeddings: 512
          initializer_range: 0.02
          layer_norm_eps: 1e-12
          pad_token_id: 0
          position_embedding_type: "absolute"
          cross_attention_frequency: 2
          encoder_hidden_size: 1408
        num_query_tokens: 32


    tokenizer_pretrained_path: /code-online/code/resources/models/bert-base-uncased
    vision_pretrain_path: /code-online/code/resources/models/blip2_vision_model.pth

